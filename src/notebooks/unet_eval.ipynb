{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e33dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815143ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_1d_array(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        arr = np.array(x)\n",
    "    else:\n",
    "        return None\n",
    "    if arr.shape == ():\n",
    "        return None\n",
    "    return arr.reshape(-1)\n",
    "\n",
    "def extract_dice_and_count(value):\n",
    "    arr = _to_1d_array(value)\n",
    "    if arr is None or arr.size == 0:\n",
    "        return None, None\n",
    "    return float(np.nanmean(arr)), int(arr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79034ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected rows: 12\n",
      "Columns found: ['file', 'dataset', 'context', 'split', 'dice', 'ece', 'case_count']\n",
      "Dice coverage: 100.0% of rows\n",
      "ECE coverage: 100.0% of rows\n",
      "\n",
      "Dice overview sample:\n",
      "split                                          test     train       val\n",
      "context                                                                \n",
      "mnmv2_scanner-symphonytim                  0.864293  0.913121  0.870260\n",
      "mnmv2_pathology-norm-vs-fall-scanners-all  0.724241  0.927814  0.906605\n",
      "pmri_threet-to-onepointfivet               0.716169  0.927362  0.862062\n",
      "pmri_promise12                             0.614633  0.926631  0.877784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3102874/1645493342.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(f, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ece",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "case_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ab5200e4-ace6-414e-97ae-42e8d3b56ddf",
       "rows": [
        [
         "0",
         "mnmv2_pathology-norm-vs-fall-scanners-all.pt",
         "mnmv2",
         "mnmv2_pathology-norm-vs-fall-scanners-all",
         "train",
         "0.9278135299682617",
         "0.023140190169215202",
         "1085"
        ],
        [
         "1",
         "mnmv2_pathology-norm-vs-fall-scanners-all.pt",
         "mnmv2",
         "mnmv2_pathology-norm-vs-fall-scanners-all",
         "val",
         "0.9066054821014404",
         "0.034563153982162476",
         "128"
        ],
        [
         "2",
         "mnmv2_pathology-norm-vs-fall-scanners-all.pt",
         "mnmv2",
         "mnmv2_pathology-norm-vs-fall-scanners-all",
         "test",
         "0.7242409586906433",
         "0.20175468921661377",
         "587"
        ],
        [
         "3",
         "mnmv2_scanner-symphonytim.pt",
         "mnmv2",
         "mnmv2_scanner-symphonytim",
         "train",
         "0.913120687007904",
         "0.026828009635210037",
         "2390"
        ],
        [
         "4",
         "mnmv2_scanner-symphonytim.pt",
         "mnmv2",
         "mnmv2_scanner-symphonytim",
         "val",
         "0.8702604174613953",
         "0.049738507717847824",
         "252"
        ],
        [
         "5",
         "mnmv2_scanner-symphonytim.pt",
         "mnmv2",
         "mnmv2_scanner-symphonytim",
         "test",
         "0.8642929792404175",
         "0.05757275968790054",
         "3470"
        ],
        [
         "6",
         "pmri_promise12.pt",
         "pmri",
         "pmri_promise12",
         "train",
         "0.9266307353973389",
         "0.19752459228038788",
         "461"
        ],
        [
         "7",
         "pmri_promise12.pt",
         "pmri",
         "pmri_promise12",
         "val",
         "0.8777843713760376",
         "0.1940927505493164",
         "64"
        ],
        [
         "8",
         "pmri_promise12.pt",
         "pmri",
         "pmri_promise12",
         "test",
         "0.6146333813667297",
         "0.2583097517490387",
         "1248"
        ],
        [
         "9",
         "pmri_threet-to-onepointfivet.pt",
         "pmri",
         "pmri_threet-to-onepointfivet",
         "train",
         "0.9273615479469299",
         "0.17346403002738953",
         "1018"
        ],
        [
         "10",
         "pmri_threet-to-onepointfivet.pt",
         "pmri",
         "pmri_threet-to-onepointfivet",
         "val",
         "0.8620617985725403",
         "0.21966974437236786",
         "103"
        ],
        [
         "11",
         "pmri_threet-to-onepointfivet.pt",
         "pmri",
         "pmri_threet-to-onepointfivet",
         "test",
         "0.7161687016487122",
         "0.26415348052978516",
         "481"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>dataset</th>\n",
       "      <th>context</th>\n",
       "      <th>split</th>\n",
       "      <th>dice</th>\n",
       "      <th>ece</th>\n",
       "      <th>case_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all</td>\n",
       "      <td>train</td>\n",
       "      <td>0.927814</td>\n",
       "      <td>0.023140</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all</td>\n",
       "      <td>val</td>\n",
       "      <td>0.906605</td>\n",
       "      <td>0.034563</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_pathology-norm-vs-fall-scanners-all</td>\n",
       "      <td>test</td>\n",
       "      <td>0.724241</td>\n",
       "      <td>0.201755</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnmv2_scanner-symphonytim.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_scanner-symphonytim</td>\n",
       "      <td>train</td>\n",
       "      <td>0.913121</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mnmv2_scanner-symphonytim.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_scanner-symphonytim</td>\n",
       "      <td>val</td>\n",
       "      <td>0.870260</td>\n",
       "      <td>0.049739</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mnmv2_scanner-symphonytim.pt</td>\n",
       "      <td>mnmv2</td>\n",
       "      <td>mnmv2_scanner-symphonytim</td>\n",
       "      <td>test</td>\n",
       "      <td>0.864293</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pmri_promise12.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_promise12</td>\n",
       "      <td>train</td>\n",
       "      <td>0.926631</td>\n",
       "      <td>0.197525</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pmri_promise12.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_promise12</td>\n",
       "      <td>val</td>\n",
       "      <td>0.877784</td>\n",
       "      <td>0.194093</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pmri_promise12.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_promise12</td>\n",
       "      <td>test</td>\n",
       "      <td>0.614633</td>\n",
       "      <td>0.258310</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pmri_threet-to-onepointfivet.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_threet-to-onepointfivet</td>\n",
       "      <td>train</td>\n",
       "      <td>0.927362</td>\n",
       "      <td>0.173464</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pmri_threet-to-onepointfivet.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_threet-to-onepointfivet</td>\n",
       "      <td>val</td>\n",
       "      <td>0.862062</td>\n",
       "      <td>0.219670</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pmri_threet-to-onepointfivet.pt</td>\n",
       "      <td>pmri</td>\n",
       "      <td>pmri_threet-to-onepointfivet</td>\n",
       "      <td>test</td>\n",
       "      <td>0.716169</td>\n",
       "      <td>0.264153</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file dataset  \\\n",
       "0   mnmv2_pathology-norm-vs-fall-scanners-all.pt   mnmv2   \n",
       "1   mnmv2_pathology-norm-vs-fall-scanners-all.pt   mnmv2   \n",
       "2   mnmv2_pathology-norm-vs-fall-scanners-all.pt   mnmv2   \n",
       "3                   mnmv2_scanner-symphonytim.pt   mnmv2   \n",
       "4                   mnmv2_scanner-symphonytim.pt   mnmv2   \n",
       "5                   mnmv2_scanner-symphonytim.pt   mnmv2   \n",
       "6                              pmri_promise12.pt    pmri   \n",
       "7                              pmri_promise12.pt    pmri   \n",
       "8                              pmri_promise12.pt    pmri   \n",
       "9                pmri_threet-to-onepointfivet.pt    pmri   \n",
       "10               pmri_threet-to-onepointfivet.pt    pmri   \n",
       "11               pmri_threet-to-onepointfivet.pt    pmri   \n",
       "\n",
       "                                      context  split      dice       ece  \\\n",
       "0   mnmv2_pathology-norm-vs-fall-scanners-all  train  0.927814  0.023140   \n",
       "1   mnmv2_pathology-norm-vs-fall-scanners-all    val  0.906605  0.034563   \n",
       "2   mnmv2_pathology-norm-vs-fall-scanners-all   test  0.724241  0.201755   \n",
       "3                   mnmv2_scanner-symphonytim  train  0.913121  0.026828   \n",
       "4                   mnmv2_scanner-symphonytim    val  0.870260  0.049739   \n",
       "5                   mnmv2_scanner-symphonytim   test  0.864293  0.057573   \n",
       "6                              pmri_promise12  train  0.926631  0.197525   \n",
       "7                              pmri_promise12    val  0.877784  0.194093   \n",
       "8                              pmri_promise12   test  0.614633  0.258310   \n",
       "9                pmri_threet-to-onepointfivet  train  0.927362  0.173464   \n",
       "10               pmri_threet-to-onepointfivet    val  0.862062  0.219670   \n",
       "11               pmri_threet-to-onepointfivet   test  0.716169  0.264153   \n",
       "\n",
       "    case_count  \n",
       "0         1085  \n",
       "1          128  \n",
       "2          587  \n",
       "3         2390  \n",
       "4          252  \n",
       "5         3470  \n",
       "6          461  \n",
       "7           64  \n",
       "8         1248  \n",
       "9         1018  \n",
       "10         103  \n",
       "11         481  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_DIR = Path('../../results/unet_eval_auto').resolve()\n",
    "pt_files = sorted([p for p in RESULT_DIR.glob('*.pt')])\n",
    "pattern_dataset = re.compile(r'^(?P<root>pmri|mnmv2)')\n",
    "\n",
    "# Rebuild results with dice + ece\n",
    "row_records = []\n",
    "for f in pt_files:\n",
    "    data = torch.load(f, map_location='cpu')\n",
    "    for split_key, metrics in data.items():\n",
    "        if not isinstance(metrics, dict):\n",
    "            continue\n",
    "        if 'dice' not in metrics:\n",
    "            continue\n",
    "        dice_val, case_count = extract_dice_and_count(metrics['dice'])\n",
    "        if dice_val is None:\n",
    "            continue\n",
    "        ece_val, _ = extract_dice_and_count(metrics.get('ece', None))\n",
    "        dataset_guess = pattern_dataset.match(f.name).group('root') if pattern_dataset.match(f.name) else 'unknown'\n",
    "        context = f.stem\n",
    "        row_records.append({\n",
    "            'file': f.name,\n",
    "            'dataset': dataset_guess,\n",
    "            'context': context,\n",
    "            'split': split_key.split('_')[-1],\n",
    "            'dice': dice_val,\n",
    "            'ece': ece_val,\n",
    "            'case_count': case_count,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(row_records)\n",
    "print('Collected rows:', len(results_df))\n",
    "print('Columns found:', results_df.columns.tolist())\n",
    "if 'dice' in results_df.columns:\n",
    "    coverage = results_df['dice'].notna().mean()\n",
    "    print(f'Dice coverage: {coverage*100:.1f}% of rows')\n",
    "if 'ece' in results_df.columns:\n",
    "    coverage = results_df['ece'].notna().mean()\n",
    "    print(f'ECE coverage: {coverage*100:.1f}% of rows')\n",
    "\n",
    "if not results_df.empty:\n",
    "    dice_overview = results_df.pivot_table(index='context', columns='split', values='dice')\n",
    "    dice_overview = dice_overview.sort_values(by=[c for c in ['test','val','train'] if c in dice_overview.columns], ascending=False)\n",
    "    print('\\nDice overview sample:')\n",
    "    print(dice_overview.head())\n",
    "else:\n",
    "    dice_overview = pd.DataFrame()\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afdc989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dice': tensor([2.4438e-01, 5.2803e-01, 8.4462e-01, 9.1397e-01, 9.2060e-01, 9.1120e-01,\n",
       "         9.3288e-01, 9.0192e-01, 8.9091e-01, 8.1924e-01, 8.5874e-01, 6.1230e-01,\n",
       "         0.0000e+00, 6.4241e-01, 8.6251e-01, 8.1441e-01, 8.5253e-01, 6.8489e-01,\n",
       "         7.1266e-01, 6.7020e-01, 6.2134e-01, 5.7256e-01, 5.7904e-01, 7.6354e-01,\n",
       "         8.7793e-01, 9.0841e-01, 8.9981e-01, 6.8159e-01, 4.5101e-01, 1.3069e-01,\n",
       "         4.0104e-01, 3.7676e-01, 1.1373e-01, 3.5430e-01, 0.0000e+00, 7.1328e-01,\n",
       "         8.6445e-01, 9.2220e-01, 9.0951e-01, 7.8850e-01, 0.0000e+00, 4.8608e-02,\n",
       "         0.0000e+00, 0.0000e+00, 6.4793e-01, 9.0452e-01, 9.1815e-01, 8.8125e-01,\n",
       "         8.9597e-01, 9.1851e-01, 8.7226e-01, 7.6442e-01, 4.8705e-01, 4.2709e-01,\n",
       "         4.6349e-01, 7.5853e-01, 7.2752e-01, 3.5294e-01, 7.6939e-01, 0.0000e+00,\n",
       "         1.2522e-01, 0.0000e+00, 5.4878e-01, 4.8256e-01, 7.5024e-01, 6.4059e-01,\n",
       "         5.2529e-01, 3.2961e-01, 7.3002e-01, 2.7809e-01, 4.7852e-02, 9.9941e-02,\n",
       "         0.0000e+00, 0.0000e+00, 9.0768e-01, 8.0280e-01, 8.1638e-01, 5.9623e-01,\n",
       "         6.7315e-02, 7.9025e-01, 8.7950e-01, 8.6296e-01, 5.2302e-01, 8.4748e-01,\n",
       "         9.1672e-01, 9.4002e-01, 6.4923e-01, 3.0191e-01, 8.2640e-01, 7.8166e-01,\n",
       "         4.4385e-01, 4.2493e-01, 8.0059e-01, 8.1650e-01, 8.7434e-01, 6.2269e-01,\n",
       "         3.8976e-01, 9.4104e-01, 7.9595e-01, 7.0546e-01, 7.6887e-01, 6.8530e-01,\n",
       "         0.0000e+00, 0.0000e+00, 8.2326e-01, 8.3672e-01, 8.6317e-01, 8.8773e-01,\n",
       "         8.2626e-01, 7.6275e-01, 5.8810e-01, 0.0000e+00, 8.8106e-01, 8.6658e-01,\n",
       "         8.9061e-01, 9.0208e-01, 7.2859e-01, 6.8868e-01, 8.5697e-01, 7.8234e-01,\n",
       "         7.2692e-01, 7.6400e-01, 7.5272e-01, 6.5059e-01, 8.1543e-01, 8.7568e-01,\n",
       "         9.1615e-01, 8.9807e-01, 8.7845e-01, 9.2256e-01, 9.2849e-01, 8.9568e-01,\n",
       "         8.6382e-01, 8.4660e-01, 7.2146e-01, 7.6239e-01, 5.2675e-02, 5.1995e-02,\n",
       "         2.2907e-01, 0.0000e+00, 2.8940e-01, 3.9864e-01, 5.3958e-01, 4.6145e-01,\n",
       "         1.5451e-01, 8.9104e-01, 8.8331e-01, 9.2702e-01, 9.3184e-01, 9.3915e-01,\n",
       "         9.0764e-01, 8.6755e-01, 8.8276e-01, 6.0932e-01, 6.2048e-01, 8.4763e-01,\n",
       "         9.1199e-01, 9.3632e-01, 9.3954e-01, 9.1813e-01, 8.4958e-01, 8.8127e-01,\n",
       "         9.0210e-01, 8.8264e-01, 8.1380e-01, 8.1232e-01, 8.3518e-01, 8.5343e-01,\n",
       "         8.8193e-01, 3.0696e-01, 8.3871e-01, 7.6086e-01, 8.8326e-01, 9.3615e-01,\n",
       "         8.9884e-01, 8.3685e-01, 8.5121e-01, 7.2233e-01, 2.9312e-01, 0.0000e+00,\n",
       "         4.4350e-01, 8.5508e-01, 8.1318e-01, 9.2278e-01, 8.5375e-01, 8.5385e-01,\n",
       "         8.4789e-01, 7.5156e-01, 8.1535e-01, 8.3130e-01, 8.4884e-01, 8.1880e-01,\n",
       "         7.9512e-01, 8.6383e-01, 7.5879e-01, 5.5497e-01, 3.1899e-01, 6.3171e-02,\n",
       "         5.2858e-01, 3.1128e-01, 4.4017e-02, 6.2169e-01, 5.7493e-01, 6.7108e-01,\n",
       "         5.3924e-01, 5.5097e-01, 4.3595e-01, 4.0259e-01, 8.1073e-01, 8.8650e-01,\n",
       "         9.3172e-01, 9.4118e-01, 9.0451e-01, 8.4272e-01, 8.3161e-01, 6.8987e-01,\n",
       "         6.9913e-01, 9.2370e-01, 9.0336e-01, 9.1806e-01, 8.8182e-01, 8.5695e-01,\n",
       "         8.8473e-01, 8.1553e-01, 6.9936e-01, 8.5042e-01, 9.1975e-01, 9.1711e-01,\n",
       "         9.2999e-01, 9.3770e-01, 9.2653e-01, 8.7384e-01, 8.4921e-01, 7.8485e-01,\n",
       "         7.5150e-01, 4.7348e-01, 0.0000e+00, 1.4090e-01, 6.0643e-01, 8.1889e-01,\n",
       "         8.6136e-01, 9.1733e-01, 8.4796e-01, 7.7303e-01, 5.6056e-01, 2.7403e-01,\n",
       "         6.6948e-01, 6.9695e-01, 2.7373e-01, 0.0000e+00, 7.6923e-01, 8.6844e-01,\n",
       "         8.8765e-01, 6.8402e-01, 7.4621e-01, 1.8131e-01, 5.9462e-01, 1.9249e-01,\n",
       "         0.0000e+00, 7.9062e-01, 6.9392e-01, 9.4759e-02, 7.8285e-01, 1.7562e-01,\n",
       "         2.9440e-01, 0.0000e+00, 0.0000e+00, 6.0698e-04, 6.4306e-01, 8.1968e-01,\n",
       "         7.8681e-01, 8.2257e-01, 9.2169e-01, 8.3287e-01, 8.4755e-01, 8.9091e-01,\n",
       "         8.2419e-01, 7.6651e-01, 3.1062e-02, 0.0000e+00, 0.0000e+00, 9.1221e-01,\n",
       "         9.0717e-01, 9.2854e-01, 9.5065e-01, 9.5376e-01, 9.4267e-01, 9.4566e-01,\n",
       "         9.5773e-01, 9.0196e-01, 8.1028e-01, 6.8901e-01, 7.3048e-01, 7.8189e-01,\n",
       "         7.2251e-01, 4.9570e-01, 8.2557e-01, 8.5750e-01, 8.5441e-01, 9.0224e-01,\n",
       "         8.3329e-01, 8.2745e-01, 7.8599e-01, 4.6012e-01, 4.2058e-01, 5.1111e-01,\n",
       "         0.0000e+00, 7.4776e-01, 9.1345e-01, 9.2976e-01, 9.2709e-01, 9.0554e-01,\n",
       "         8.9563e-01, 7.0771e-01, 2.9383e-01, 3.9698e-01, 8.2294e-01, 8.8876e-01,\n",
       "         8.9339e-01, 9.0721e-01, 8.4124e-01, 7.5469e-01, 7.4877e-01, 2.9077e-01,\n",
       "         6.5879e-01, 8.2173e-01, 8.7382e-01, 9.1732e-01, 9.6691e-01, 9.3531e-01,\n",
       "         9.3992e-01, 8.0739e-01, 7.9007e-01, 8.7494e-01, 6.7614e-01, 5.9105e-01,\n",
       "         8.4276e-01, 8.4468e-01, 9.3296e-01, 8.7973e-01, 9.1878e-01, 9.3175e-01,\n",
       "         9.4401e-01, 9.1711e-01, 9.0718e-01, 8.6042e-01, 6.1653e-01, 2.6226e-01,\n",
       "         7.1588e-01, 8.0654e-01, 8.2766e-01, 8.9198e-01, 8.9486e-01, 9.0997e-01,\n",
       "         9.3797e-01, 8.8094e-01, 8.3454e-01, 8.5446e-01, 8.2862e-01, 3.5325e-01,\n",
       "         8.3052e-01, 7.8320e-01, 8.6692e-01, 8.2815e-01, 8.7662e-01, 8.9569e-01,\n",
       "         8.8789e-01, 9.0863e-01, 8.8043e-01, 9.0001e-01, 8.6710e-01, 9.3129e-01,\n",
       "         6.4198e-01, 5.7477e-01, 8.5863e-01, 8.7476e-01, 8.9918e-01, 9.2546e-01,\n",
       "         9.2003e-01, 9.1279e-01, 8.7866e-01, 9.0120e-01, 9.3603e-01, 9.3294e-01,\n",
       "         9.2419e-01, 9.2588e-01, 8.3670e-01, 8.7310e-01, 8.9599e-01, 7.5549e-01,\n",
       "         7.4684e-01, 3.6743e-01, 0.0000e+00, 6.2699e-01, 7.6490e-01, 8.8281e-01,\n",
       "         9.4590e-01, 9.1915e-01, 9.2572e-01, 9.3197e-01, 9.2123e-01, 9.5671e-01,\n",
       "         9.5040e-01, 9.4987e-01, 9.0499e-01, 8.7235e-01, 9.2241e-01, 7.4109e-01,\n",
       "         6.6573e-01, 8.8263e-01, 8.8565e-01, 8.3900e-01, 8.4730e-01, 9.0701e-01,\n",
       "         8.7631e-01, 8.8657e-01, 9.0743e-01, 9.0397e-01, 9.0717e-01, 8.7403e-01,\n",
       "         8.6787e-01, 8.1692e-01, 5.2365e-01, 8.6498e-01, 9.1687e-01, 9.3234e-01,\n",
       "         9.5306e-01, 9.3722e-01, 9.2349e-01, 9.1653e-01, 8.8788e-01, 7.1061e-01,\n",
       "         2.3819e-01, 4.8362e-01, 7.5506e-01, 8.5669e-01, 7.7103e-01, 7.5745e-01,\n",
       "         7.6579e-01, 8.1452e-01, 8.5730e-01, 8.1415e-01, 8.5942e-01, 8.8155e-01,\n",
       "         8.3912e-01, 7.7167e-01, 4.2449e-01, 9.0931e-01, 8.9762e-01, 9.1100e-01,\n",
       "         9.4081e-01, 8.9399e-01, 9.6602e-01, 9.4578e-01, 9.4870e-01, 9.2468e-01,\n",
       "         9.0685e-01, 6.7321e-01, 3.1638e-01, 7.6164e-01, 7.5356e-01, 8.8093e-01,\n",
       "         8.8427e-01, 9.1157e-01, 9.3106e-01, 9.5648e-01, 8.8502e-01, 8.6487e-01,\n",
       "         6.7631e-01, 4.7332e-01, 8.1029e-01, 8.5024e-01, 8.0999e-01, 9.0102e-01,\n",
       "         9.1937e-01, 8.9659e-01, 9.0735e-01, 9.2109e-01, 9.0024e-01, 6.5004e-01,\n",
       "         6.2661e-01]),\n",
       " 'loss': [tensor(0.4009),\n",
       "  tensor(0.5988),\n",
       "  tensor(0.4958),\n",
       "  tensor(0.3797),\n",
       "  tensor(0.3767),\n",
       "  tensor(0.3150),\n",
       "  tensor(0.4175),\n",
       "  tensor(0.4254),\n",
       "  tensor(0.5524),\n",
       "  tensor(0.3347),\n",
       "  tensor(0.2382),\n",
       "  tensor(0.1875),\n",
       "  tensor(0.2208),\n",
       "  tensor(0.2465),\n",
       "  tensor(0.2115),\n",
       "  tensor(0.5114)],\n",
       " 'surface_dice': tensor([0.2181, 0.2150, 0.4486, 0.6040, 0.6418, 0.6553, 0.7107, 0.5117, 0.3763,\n",
       "         0.3204, 0.5975, 0.1697, 0.0000, 0.3447, 0.4696, 0.2860, 0.3609, 0.2794,\n",
       "         0.3346, 0.1804, 0.2075, 0.4436, 0.2406, 0.3079, 0.5589, 0.7269, 0.7014,\n",
       "         0.2725, 0.0000, 0.0868, 0.1166, 0.1941, 0.0000, 0.3730, 0.0000, 0.4941,\n",
       "         0.5587, 0.7545, 0.6799, 0.5411, 0.0000, 0.0194, 0.0000, 0.0000, 0.3103,\n",
       "         0.5165, 0.5773, 0.2978, 0.2940, 0.4924, 0.4031, 0.2315, 0.1063, 0.0805,\n",
       "         0.2633, 0.3531, 0.5029, 0.1058, 0.3188, 0.0000, 0.1013, 0.0000, 0.2877,\n",
       "         0.0233, 0.2049, 0.1254, 0.1329, 0.1489, 0.2601, 0.1255, 0.0807, 0.3257,\n",
       "         0.0000, 0.0000, 0.6192, 0.4294, 0.3250, 0.1685, 0.0955, 0.1576, 0.5319,\n",
       "         0.4274, 0.3742, 0.5103, 0.6155, 0.7283, 0.4061, 0.1805, 0.3820, 0.4555,\n",
       "         0.0491, 0.2315, 0.4809, 0.4332, 0.5287, 0.2657, 0.0960, 0.7778, 0.2446,\n",
       "         0.1962, 0.3874, 0.3167, 0.0000, 0.0000, 0.5309, 0.3395, 0.6369, 0.5116,\n",
       "         0.2890, 0.3401, 0.1602, 0.0000, 0.4100, 0.3796, 0.2149, 0.3560, 0.2344,\n",
       "         0.1776, 0.1065, 0.0586, 0.0812, 0.3065, 0.1168, 0.1922, 0.5468, 0.4608,\n",
       "         0.5113, 0.3654, 0.4394, 0.5014, 0.5517, 0.5836, 0.4371, 0.4170, 0.1869,\n",
       "         0.1980, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1094, 0.0376,\n",
       "         0.1003, 0.6276, 0.5648, 0.7338, 0.7175, 0.7744, 0.5585, 0.3075, 0.6800,\n",
       "         0.2740, 0.2912, 0.3384, 0.7044, 0.6601, 0.6782, 0.4918, 0.4324, 0.5065,\n",
       "         0.4566, 0.5390, 0.1437, 0.3178, 0.3217, 0.5521, 0.8125, 0.0971, 0.6176,\n",
       "         0.3522, 0.5364, 0.7545, 0.5383, 0.3654, 0.6058, 0.2924, 0.1267, 0.0000,\n",
       "         0.1130, 0.5667, 0.2902, 0.7185, 0.4163, 0.4058, 0.4757, 0.1328, 0.2030,\n",
       "         0.3281, 0.2953, 0.1705, 0.2382, 0.2404, 0.3844, 0.1519, 0.1017, 0.0906,\n",
       "         0.1633, 0.1177, 0.0000, 0.1393, 0.0928, 0.1698, 0.1501, 0.0536, 0.0540,\n",
       "         0.0045, 0.4691, 0.4974, 0.7293, 0.8652, 0.5034, 0.2459, 0.1770, 0.3731,\n",
       "         0.3139, 0.7203, 0.6404, 0.7432, 0.5512, 0.4894, 0.5066, 0.3418, 0.2947,\n",
       "         0.5044, 0.4821, 0.5188, 0.5909, 0.6008, 0.5428, 0.1720, 0.1541, 0.0559,\n",
       "         0.1035, 0.1814, 0.0000, 0.0812, 0.2264, 0.5513, 0.6078, 0.6679, 0.4090,\n",
       "         0.1681, 0.0000, 0.1095, 0.0063, 0.2366, 0.1121, 0.0000, 0.1421, 0.5930,\n",
       "         0.5515, 0.2675, 0.3309, 0.1057, 0.2238, 0.0109, 0.0000, 0.5071, 0.3651,\n",
       "         0.0302, 0.3060, 0.0525, 0.1966, 0.0000, 0.0000, 0.0593, 0.1569, 0.4545,\n",
       "         0.3340, 0.4974, 0.6740, 0.3275, 0.2266, 0.4403, 0.2413, 0.3790, 0.0000,\n",
       "         0.0000, 0.0000, 0.4788, 0.3703, 0.4895, 0.6378, 0.6844, 0.6242, 0.5956,\n",
       "         0.6680, 0.3852, 0.2288, 0.1017, 0.0000, 0.2011, 0.1446, 0.3455, 0.4785,\n",
       "         0.4791, 0.4873, 0.5722, 0.2683, 0.4411, 0.2306, 0.2480, 0.2428, 0.2789,\n",
       "         0.0000, 0.3398, 0.6513, 0.7477, 0.6560, 0.6303, 0.5236, 0.2712, 0.0000,\n",
       "         0.2218, 0.4100, 0.4675, 0.5345, 0.5417, 0.4831, 0.3455, 0.4354, 0.2041,\n",
       "         0.2146, 0.6046, 0.6342, 0.8314, 1.0000, 0.8180, 0.9339, 0.4059, 0.3966,\n",
       "         0.6422, 0.1774, 0.1976, 0.5779, 0.5390, 0.8490, 0.5694, 0.7574, 0.7011,\n",
       "         0.7449, 0.5736, 0.5694, 0.3934, 0.1116, 0.1287, 0.4639, 0.4866, 0.4467,\n",
       "         0.7011, 0.5980, 0.5708, 0.7172, 0.4442, 0.0992, 0.5325, 0.4596, 0.1461,\n",
       "         0.6398, 0.5532, 0.7411, 0.5102, 0.5318, 0.6037, 0.4674, 0.5342, 0.3791,\n",
       "         0.5317, 0.4674, 0.7656, 0.2573, 0.1682, 0.6449, 0.6158, 0.6218, 0.6477,\n",
       "         0.5712, 0.4736, 0.2767, 0.3155, 0.6494, 0.4969, 0.5542, 0.5693, 0.2806,\n",
       "         0.2989, 0.4176, 0.1379, 0.1568, 0.2822, 0.0000, 0.1550, 0.2690, 0.4649,\n",
       "         0.8543, 0.6402, 0.6248, 0.7316, 0.6522, 0.7802, 0.7565, 0.7571, 0.4428,\n",
       "         0.2855, 0.6306, 0.2882, 0.3476, 0.7592, 0.6768, 0.4813, 0.4758, 0.7097,\n",
       "         0.3939, 0.4869, 0.5280, 0.5787, 0.5695, 0.5228, 0.4225, 0.2836, 0.1576,\n",
       "         0.5933, 0.7114, 0.7393, 0.8737, 0.7407, 0.6848, 0.5147, 0.4919, 0.1089,\n",
       "         0.1715, 0.2053, 0.3830, 0.6275, 0.5183, 0.3692, 0.2788, 0.4157, 0.5594,\n",
       "         0.3553, 0.4022, 0.4309, 0.4092, 0.3473, 0.0000, 0.7869, 0.7025, 0.6810,\n",
       "         0.8762, 0.5306, 0.9076, 0.8316, 0.8889, 0.6928, 0.6180, 0.3105, 0.1412,\n",
       "         0.4602, 0.4708, 0.6761, 0.5775, 0.6888, 0.8271, 0.9456, 0.6406, 0.6056,\n",
       "         0.3134, 0.3736, 0.6423, 0.7405, 0.6091, 0.7525, 0.7576, 0.5292, 0.6583,\n",
       "         0.6585, 0.5764, 0.0753, 0.2708]),\n",
       " 'entropy': tensor([0.9970, 0.9968, 0.9968, 0.9968, 0.9961, 0.9960, 0.9962, 0.9959, 0.9948,\n",
       "         0.9964, 0.9976, 0.9967, 0.9966, 0.9983, 0.9982, 0.9979, 0.9965, 0.9925,\n",
       "         0.9971, 0.9969, 0.9969, 0.9964, 0.9984, 0.9980, 0.9978, 0.9976, 0.9971,\n",
       "         0.9961, 0.9961, 0.9926, 0.9980, 0.9898, 0.9963, 0.9955, 0.9960, 0.9983,\n",
       "         0.9978, 0.9977, 0.9972, 0.9971, 0.9959, 0.9898, 0.9971, 0.9985, 0.9976,\n",
       "         0.9973, 0.9961, 0.9950, 0.9953, 0.9948, 0.9944, 0.9939, 0.9967, 0.9963,\n",
       "         0.9967, 0.9975, 0.9946, 0.9895, 0.9940, 0.9979, 0.9960, 0.9991, 0.9967,\n",
       "         0.9958, 0.9969, 0.9926, 0.9860, 0.9891, 0.9922, 0.9817, 0.9966, 0.9949,\n",
       "         0.9939, 0.9943, 0.9971, 0.9972, 0.9940, 0.9880, 0.9906, 0.9955, 0.9968,\n",
       "         0.9964, 0.9978, 0.9973, 0.9971, 0.9966, 0.9857, 0.9887, 0.9966, 0.9931,\n",
       "         0.9934, 0.9982, 0.9980, 0.9981, 0.9973, 0.9902, 0.9870, 0.9968, 0.9955,\n",
       "         0.9968, 0.9984, 0.9987, 0.9960, 0.9978, 0.9977, 0.9978, 0.9977, 0.9969,\n",
       "         0.9971, 0.9957, 0.9934, 0.9948, 0.9946, 0.9928, 0.9924, 0.9899, 0.9880,\n",
       "         0.9884, 0.9904, 0.9912, 0.9942, 0.9945, 0.9957, 0.9980, 0.9977, 0.9972,\n",
       "         0.9972, 0.9967, 0.9963, 0.9961, 0.9959, 0.9945, 0.9952, 0.9939, 0.9959,\n",
       "         0.9959, 0.9958, 0.9935, 0.9950, 0.9977, 0.9929, 0.9970, 0.9955, 0.9920,\n",
       "         0.9952, 0.9980, 0.9978, 0.9976, 0.9974, 0.9973, 0.9972, 0.9968, 0.9972,\n",
       "         0.9969, 0.9976, 0.9965, 0.9956, 0.9953, 0.9947, 0.9950, 0.9935, 0.9944,\n",
       "         0.9955, 0.9963, 0.9974, 0.9976, 0.9973, 0.9983, 0.9989, 0.9980, 0.9979,\n",
       "         0.9955, 0.9977, 0.9972, 0.9971, 0.9950, 0.9953, 0.9931, 0.9958, 0.9957,\n",
       "         0.9952, 0.9909, 0.9927, 0.9948, 0.9936, 0.9932, 0.9934, 0.9916, 0.9947,\n",
       "         0.9945, 0.9948, 0.9956, 0.9937, 0.9969, 0.9978, 0.9985, 0.9910, 0.9888,\n",
       "         0.9883, 0.9880, 0.9924, 0.9935, 0.9928, 0.9960, 0.9963, 0.9970, 0.9982,\n",
       "         0.9961, 0.9976, 0.9972, 0.9976, 0.9975, 0.9974, 0.9977, 0.9977, 0.9969,\n",
       "         0.9980, 0.9977, 0.9976, 0.9972, 0.9965, 0.9961, 0.9968, 0.9976, 0.9966,\n",
       "         0.9933, 0.9931, 0.9904, 0.9924, 0.9941, 0.9925, 0.9937, 0.9944, 0.9956,\n",
       "         0.9969, 0.9967, 0.9916, 0.9959, 0.9966, 0.9955, 0.9947, 0.9965, 0.9972,\n",
       "         0.9971, 0.9976, 0.9915, 0.9967, 0.9962, 0.9917, 0.9964, 0.9980, 0.9979,\n",
       "         0.9974, 0.9912, 0.9939, 0.9918, 0.9937, 0.9927, 0.9950, 0.9979, 0.9987,\n",
       "         0.9891, 0.9969, 0.9938, 0.9938, 0.9941, 0.9918, 0.9956, 0.9968, 0.9973,\n",
       "         0.9968, 0.9959, 0.9958, 0.9938, 0.9930, 0.9949, 0.9952, 0.9941, 0.9933,\n",
       "         0.9904, 0.9819, 0.9954, 0.9954, 0.9940, 0.9943, 0.9939, 0.9941, 0.9939,\n",
       "         0.9935, 0.9922, 0.9933, 0.9927, 0.9944, 0.9955, 0.9956, 0.9980, 0.9953,\n",
       "         0.9980, 0.9975, 0.9962, 0.9955, 0.9964, 0.9975, 0.9972, 0.9967, 0.9975,\n",
       "         0.9978, 0.9981, 0.9978, 0.9974, 0.9973, 0.9962, 0.9944, 0.9942, 0.9968,\n",
       "         0.9973, 0.9979, 0.9972, 0.9962, 0.9968, 0.9956, 0.9971, 0.9974, 0.9958,\n",
       "         0.9986, 0.9987, 0.9986, 0.9983, 0.9980, 0.9978, 0.9977, 0.9975, 0.9972,\n",
       "         0.9974, 0.9982, 0.9982, 0.9985, 0.9981, 0.9980, 0.9977, 0.9973, 0.9971,\n",
       "         0.9967, 0.9967, 0.9967, 0.9970, 0.9963, 0.9969, 0.9982, 0.9985, 0.9984,\n",
       "         0.9982, 0.9981, 0.9977, 0.9976, 0.9973, 0.9971, 0.9966, 0.9972, 0.9975,\n",
       "         0.9987, 0.9986, 0.9985, 0.9983, 0.9978, 0.9975, 0.9972, 0.9969, 0.9964,\n",
       "         0.9956, 0.9963, 0.9964, 0.9958, 0.9987, 0.9986, 0.9984, 0.9979, 0.9970,\n",
       "         0.9968, 0.9962, 0.9958, 0.9956, 0.9954, 0.9944, 0.9944, 0.9950, 0.9957,\n",
       "         0.9968, 0.9968, 0.9963, 0.9973, 0.9890, 0.9885, 0.9931, 0.9980, 0.9978,\n",
       "         0.9977, 0.9972, 0.9966, 0.9958, 0.9955, 0.9955, 0.9958, 0.9958, 0.9954,\n",
       "         0.9959, 0.9950, 0.9975, 0.9987, 0.9985, 0.9986, 0.9984, 0.9982, 0.9979,\n",
       "         0.9978, 0.9975, 0.9973, 0.9973, 0.9971, 0.9966, 0.9963, 0.9966, 0.9982,\n",
       "         0.9980, 0.9977, 0.9971, 0.9972, 0.9971, 0.9968, 0.9969, 0.9963, 0.9954,\n",
       "         0.9934, 0.9966, 0.9979, 0.9987, 0.9986, 0.9986, 0.9983, 0.9981, 0.9977,\n",
       "         0.9946, 0.9969, 0.9973, 0.9967, 0.9958, 0.9921, 0.9983, 0.9981, 0.9980,\n",
       "         0.9978, 0.9976, 0.9971, 0.9974, 0.9973, 0.9975, 0.9976, 0.9973, 0.9936,\n",
       "         0.9988, 0.9985, 0.9984, 0.9983, 0.9982, 0.9981, 0.9981, 0.9978, 0.9978,\n",
       "         0.9977, 0.9957, 0.9985, 0.9985, 0.9984, 0.9981, 0.9980, 0.9976, 0.9974,\n",
       "         0.9972, 0.9955, 0.9943, 0.9926]),\n",
       " 'ece': [tensor(0.6726),\n",
       "  tensor(0.5512),\n",
       "  tensor(0.5476),\n",
       "  tensor(0.6759),\n",
       "  tensor(0.6865),\n",
       "  tensor(0.7013),\n",
       "  tensor(0.5942),\n",
       "  tensor(0.6850),\n",
       "  tensor(0.6324),\n",
       "  tensor(0.6985),\n",
       "  tensor(0.7844),\n",
       "  tensor(0.8276),\n",
       "  tensor(0.7926),\n",
       "  tensor(0.8355),\n",
       "  tensor(0.8735),\n",
       "  tensor(0.8296)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
